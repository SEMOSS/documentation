"use strict";(self.webpackChunkcfg_docs=self.webpackChunkcfg_docs||[]).push([[2361],{29859:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>a,metadata:()=>o,toc:()=>c});var r=n(74848),s=n(28453);const a={sidebar_label:"Streamlit App Quickstart Guide",sidebar_position:2},i="Creating a GenAI app using Streamlit",o={id:"How To/App Creation Guides/Streamlit App Quickstart Guide",title:"Creating a GenAI app using Streamlit",description:"Overview",source:"@site/docs/How To/App Creation Guides/Streamlit App Quickstart Guide.md",sourceDirName:"How To/App Creation Guides",slug:"/How To/App Creation Guides/Streamlit App Quickstart Guide",permalink:"/documentation/How To/App Creation Guides/Streamlit App Quickstart Guide",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"Streamlit App Quickstart Guide",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"React App - Quickstart Guide",permalink:"/documentation/How To/App Creation Guides/React App Quickstart Guide"},next:{title:"Drag and Drop",permalink:"/documentation/drag-and-drop"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Generate Access Key from your AI server",id:"generate-access-key-from-your-ai-server",level:2},{value:"Install the Streamlit and AI Server Packages",id:"install-the-streamlit-and-ai-server-packages",level:2},{value:"Integrate with Streamlit",id:"integrate-with-streamlit",level:2},{value:"Step 1: <strong>Clone the Chatbot.py code</strong>",id:"step-1-clone-the-chatbotpy-code",level:3},{value:"Step 2: <strong>Removing the openai import and replacing it with ai_server</strong>",id:"step-2-removing-the-openai-import-and-replacing-it-with-ai_server",level:3},{value:"Step 3: <strong>Create a login function</strong>",id:"step-3-create-a-login-function",level:3},{value:"Step 4: <strong>Updating the side bar</strong>",id:"step-4-updating-the-side-bar",level:3},{value:"Step 5: <strong>Redefine safety checks before inference calls</strong>",id:"step-5-redefine-safety-checks-before-inference-calls",level:3},{value:"Step 6: <strong>Update the payload logic</strong>",id:"step-6-update-the-payload-logic",level:3},{value:"What&#39;s Next?",id:"whats-next",level:3}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h1,{id:"creating-a-genai-app-using-streamlit",children:"Creating a GenAI app using Streamlit"}),"\n",(0,r.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(t.p,{children:"Streamlit is an open-source Python library that makes it easy to create custom web apps for machine learning and data science. Its a very useful tool for Data Scientists and Analysts to create analytical models and to query large databases."}),"\n",(0,r.jsx)(t.p,{children:"Streamlit has its own documentation that goes through its functionality and implementation. Its useful to go through and look through that here:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://docs.streamlit.io/",children:"Streamlit Documentation"})}),"\n",(0,r.jsx)(t.p,{children:"Futhermore, Streamlit has a great gallery of apps that users have created. Its a useful repository of ideas and concepts that many find helpful:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://streamlit.io/gallery",children:"Apps Gallery"})}),"\n",(0,r.jsxs)(t.p,{children:["Please note that as of now there is no native integration of Streamlit as a hosted SEMOSS app. However, Streamlit is very useful for quick presentations and Proof-of-Concept creations. Converting them into a SEMOSS app would require using either the ",(0,r.jsx)(t.a,{href:"/documentation/How%20To/App%20Creation%20Guides/VanillaJS%20App%20Quickstart%20Guide",children:"VanillaJS Use Case"})," or the ",(0,r.jsx)(t.a,{href:"/documentation/How%20To/App%20Creation%20Guides/React%20App%20Quickstart%20Guide",children:"React Use Case"}),". In the future there will be a Streamlit conversion guide that will be a more comprehensive guide for converting a streamlit app into a hosted SEMOSS app."]}),"\n",(0,r.jsx)(t.p,{children:"You are, however, able to connect a Streamlit app to use the Models, Databases, and Storage Catalogs that are present in your SEMOSS server. This guide will go through and show how to run a local Streamlit app using your SEMOSS data."}),"\n",(0,r.jsx)(t.p,{children:"It is important to keep in mind that Streamlit also requires a running backend server."}),"\n",(0,r.jsx)(t.h1,{id:"installation-guide",children:"Installation Guide"}),"\n",(0,r.jsx)(t.h2,{id:"generate-access-key-from-your-ai-server",children:"Generate Access Key from your AI server"}),"\n",(0,r.jsx)(t.p,{children:"The first step to gaining access to the data stored in your SEMOSS server is to generate an access key and a secret key. To do this, click on the link below. After you have generated your keys, navigate back to this guide to complete your Streamlit integration."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"/documentation/How%20To/Establish%20Connection%20to%20CFG%20Portal/Connecting%20to%20CFG%20AI",children:"Generate Access Key"})}),"\n",(0,r.jsx)(t.h2,{id:"install-the-streamlit-and-ai-server-packages",children:"Install the Streamlit and AI Server Packages"}),"\n",(0,r.jsx)(t.p,{children:"Open up a command prompt or terminal.\r\nThen, run the following commands to install Streamlit and AI Server:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"pip install streamlit\r\npip install ai-server-sdk\n"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Note"}),"\r\nThis guide assumes that you already have Python (3.9+) and pip installed. If you do not, please follow the ",(0,r.jsx)(t.a,{href:"/documentation/Advanced%20Installation/Local%20BE%20Install%20Guide",children:"Back End Setup"})," section first."]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"integrate-with-streamlit",children:"Integrate with Streamlit"}),"\n",(0,r.jsx)(t.p,{children:"In this example we will take an existing streamlit app and modify it to be compatible with the SEMOSS server instead of Open AI."}),"\n",(0,r.jsxs)(t.h3,{id:"step-1-clone-the-chatbotpy-code",children:["Step 1: ",(0,r.jsx)(t.strong,{children:"Clone the Chatbot.py code"})]}),"\n",(0,r.jsxs)(t.p,{children:["We are going to create a simple app that has a conversation with a given LLM or Model Engine. We cloned the code from ",(0,r.jsx)(t.a,{href:"https://github.com/streamlit/llm-examples/blob/main/Chatbot.py",children:"Chatbot.py"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"The starting code is as follows:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import openai\r\nimport streamlit as st\r\n\r\nwith st.sidebar:\r\n    openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")\r\n    "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"\r\n    "[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)"\r\n    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)"\r\n\r\nst.title("\ud83d\udcac Chatbot")\r\nst.caption("\ud83d\ude80 A streamlit chatbot powered by OpenAI LLM")\r\nif "messages" not in st.session_state:\r\n    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]\r\n\r\nfor msg in st.session_state.messages:\r\n    st.chat_message(msg["role"]).write(msg["content"])\r\n\r\nif prompt := st.chat_input():\r\n    if not openai_api_key:\r\n        st.info("Please add your OpenAI API key to continue.")\r\n        st.stop()\r\n\r\n    openai.api_key = openai_api_key\r\n    st.session_state.messages.append({"role": "user", "content": prompt})\r\n    st.chat_message("user").write(prompt)\r\n    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=st.session_state.messages)\r\n    msg = response.choices[0].message\r\n    st.session_state.messages.append(msg)\r\n    st.chat_message("assistant").write(msg.content)\n'})}),"\n",(0,r.jsx)(t.p,{children:"The original Streamlit App looked like this -"}),"\n",(0,r.jsx)("img",{width:"958",alt:"original-chatbot-app",src:"../../../static/img/StreamlitImages/ai-server-chatbot-app.png"}),"\n",(0,r.jsx)(t.p,{children:"We are going to make it use the AI Server's Model Engine Catalog by implementing the changes mentioned below -"}),"\n",(0,r.jsx)("img",{width:"251",alt:"Update Steps",src:"../../../static/img/StreamlitImages/update-steps.png"}),"\n",(0,r.jsxs)(t.h3,{id:"step-2-removing-the-openai-import-and-replacing-it-with-ai_server",children:["Step 2: ",(0,r.jsx)(t.strong,{children:"Removing the openai import and replacing it with ai_server"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"## Change 1 ##\r\n# Replace openai package with ai_server\r\nimport ai_server\r\nimport streamlit as st\n"})}),"\n",(0,r.jsx)(t.p,{children:"The ai_server function"}),"\n",(0,r.jsxs)(t.h3,{id:"step-3-create-a-login-function",children:["Step 3: ",(0,r.jsx)(t.strong,{children:"Create a login function"})]}),"\n",(0,r.jsx)(t.p,{children:"Every api call that is made usually requires some level of authentication. In order to avoid this, we are can create a caching function that stores our access and secret keys and stops streamlit from re-executing the login call."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'## Change 2 ##\r\n# Create a function to login into the server using your access keys\r\n@st.cache_resource # Use st.cache to cache the server authentication logic\r\ndef login(secret_key, access_key, ai_server_url):\r\n    try:\r\n        # Attempt to create the server connection. If there is an error when connecting then an error will be raised\r\n        conn = ai_server.RESTServer(\r\n            access_key=access_key,\r\n            secret_key=secret_key,\r\n            base=ai_server_url\r\n        )\r\n        return conn\r\n    except:\r\n        # If login fails, display an error message\r\n        st.error("Login failed")\n'})}),"\n",(0,r.jsxs)(t.h3,{id:"step-4-updating-the-side-bar",children:["Step 4: ",(0,r.jsx)(t.strong,{children:"Updating the side bar"})]}),"\n",(0,r.jsxs)(t.p,{children:["Instead of providing a secret key for Open AI we will change the inputs to match the AI Server login requirements and indicate which model engine you would like to inference with. ",(0,r.jsx)(t.em,{children:"Some of these fields can be hard coded depending on the use case"}),"."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'## Change 3 ##\r\nst.title("\ud83d\udcac Chatbot")\r\n# Change the display reference from OpenAI LLM to SEMOSS Server\r\nst.caption("\ud83d\ude80 A streamlit chatbot powered by SEMOSS Server")\r\n\r\n# Remove OpenAI secret and add additional inputs in the side bar menu\r\nwith st.sidebar:\r\n    ai_server_url = st.text_input("AI Server URL")                          # Your backend endpoint\r\n    secret_key = st.text_input("Secret Key", type="password")               # Your AI Server Secret Key\r\n    access_key = st.text_input("Access Key", type="password")               # Your AI Server Access Key\r\n    engine_id = st.text_input("Model Engine ID", key="model_engine_id")     # The model engine ID\r\n    server_connection = login(secret_key, access_key, ai_server_url)        # make the loging call\n'})}),"\n",(0,r.jsx)(t.p,{children:"Currently Streamlit apps can only interact with SEMOSS when you are running an instance of SEMOSS locally. As such, you need point your server to your backend. In most instances this will be the Monolith server that you setup and run."}),"\n",(0,r.jsx)(t.p,{children:"If you were actively developing then you might want to consider hard coding your access credentials so that you don't have to enter them every time. That change would look as follow:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Harcoded Example of the above\r\n# Remove OpenAI secret and add additional inputs in the side bar menu\r\nwith st.sidebar:\r\n    ai_server_url = "<your monolith endpoint>"                              # Your Monolith endpoint\r\n    secret_key = "<your secret key>"                                        # Your AI Server Secret Key\r\n    access_key = "<your access key>"                                        # Your AI Server Access Key\r\n    engine_id = st.text_input("Model Engine ID", key="model_engine_id")     # The model engine ID\r\n    server_connection = login(secret_key, access_key, ai_server_url)        # make the loging call\n'})}),"\n",(0,r.jsxs)(t.h3,{id:"step-5-redefine-safety-checks-before-inference-calls",children:["Step 5: ",(0,r.jsx)(t.strong,{children:"Redefine safety checks before inference calls"})]}),"\n",(0,r.jsx)(t.p,{children:"Instead of requiring an OpenAI secret key, we will ensure that the user was able to connect to the server and provided a model engine ID."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'## Change 4 ##\r\n# When the prompt is provided, make the connection was established and an engine ID was provided\r\nif prompt := st.chat_input():\r\n    if not server_connection:\r\n        st.warning("Please login before trying to make an inference call.")\r\n        st.stop()\r\n\r\n    if not engine_id:\r\n        st.info("Please add Model Engine ID.")\r\n        st.stop()\n'})}),"\n",(0,r.jsxs)(t.h3,{id:"step-6-update-the-payload-logic",children:["Step 6: ",(0,r.jsx)(t.strong,{children:"Update the payload logic"})]}),"\n",(0,r.jsx)(t.p,{children:"Finally we just need to change the way we are accessing and recording the response from the model engine."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'    ## Change 5 ##\r\n    ## Create a reference to the model engine ##\r\n    model = ai_server.ModelEngine(engine_id = engine_id, insight_id = server_connection.cur_insight)\r\n\r\n    # No changes here\r\n    st.session_state.messages.append({"role": "user", "content": prompt})\r\n    st.chat_message("user").write(prompt)\r\n\r\n    # update the inference call to use ModelEngine\r\n    response = model.ask(question = prompt)\r\n    # Get the output string from the response\r\n    msg = response[0][\'response\']\r\n    # match the dictionary responses for OpenAI\r\n    st.session_state.messages.append({"role": "assistant", "content": msg})\r\n    st.chat_message("assistant").write(msg)\n'})}),"\n",(0,r.jsx)(t.p,{children:"The final result is as follows:"}),"\n",(0,r.jsx)("img",{width:"959",alt:"ai-server-chatbot-app",src:"../../../static/img/StreamlitImages/ai-server-chatbot-app.png"}),"\n",(0,r.jsx)(t.p,{children:"Full code for implementing above changes can be found here"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://github.com/Deloitte-Default/cfgai-docs/blob/main/streamlit/CFG_Chatbot.py",children:"Chatbot.py Full code"})}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Note"}),"\r\nThis is a protected GitHub, if you do not have access to it, or are not currently signed in to your GitHub account you will get a 404 Error. Ask an admin for access."]}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"whats-next",children:"What's Next?"}),"\n",(0,r.jsx)(t.p,{children:"Finished with this guide?"}),"\n",(0,r.jsx)(t.p,{children:"Try out an App Use Case Quick Start guide for a different frontend framework linked below!"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"/documentation/How%20To/App%20Creation%20Guides/React%20App%20Quickstart%20Guide",children:"React Quick Start Guide"})}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"/documentation/How%20To/App%20Creation%20Guides/VanillaJS%20App%20Quickstart%20Guide",children:"Sample VanillaJS Use Case"})}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var r=n(96540);const s={},a=r.createContext(s);function i(e){const t=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(a.Provider,{value:t},e.children)}}}]);