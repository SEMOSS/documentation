---
sidebar_label: 'LLM Hosting Options'
sidebar_position: 4
---

# LLM Hosting Options

## vLLM: Fast and User-Friendly LLM Library
vLLM is designed for rapid Large Language Model (LLM) inference and serving. 
For comprehensive documentation and further details, please visit [here](https://docs.vllm.ai/en/latest/).

## Text Generation Inference (TGI)
Text Generation Inference (TGI) stands as a versatile toolkit crafted for the seamless deployment and efficient serving of Large Language Models (LLMs). By harnessing the power of TGI, users can unlock unparalleled performance in text generation. TGI is meticulously designed to cater to a wide array of the most renowned open-source LLMs, such as Llama, Falcon, StarCoder, BLOOM, GPT-NeoX, and beyond.
For further exploration and detailed documentation, visit [here](https://huggingface.co/docs/text-generation-inference/index).